{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and matplotlib, and use jupyter magic to\n",
    "# get plots directly in notebook\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time, sleep\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some general concepts: map and reduce\n",
    "\n",
    "\n",
    "### Map\n",
    "A map is essentially a function that takes some input, and produces some output (as most functions do), thus mapping from an input space to an output space.\n",
    "\n",
    "Python provides a built-in function called `map` which applies another function to a list of arguments. Note that this is shown here mainly as an example of the concept of mapping from input to output, not because it is a particularly good idea to use `map`. You can usually find more readable ways to do the same.\n",
    "\n",
    "### Reduce\n",
    "A reduction uses an associative operation (associative means order of operands doesn't matter) to reduce a list of inputs to a single value. Common examples include taking the sum of a list of numbers, or a product of a list of numbers.\n",
    "\n",
    "Python provides a function called `reduce` from the module `functools`. It takes a binary function (a function of two arguments), and applies it repeatedly to a list of inputs until one one value remains. Again, I include this here mainly as an example of the concept of reducing a list of inputs, not because it is a particularly good idea to use `reduce`. You can usually find more readable ways to do the same.\n",
    "\n",
    "### MapReduce\n",
    "Problems that can be formulated as a mapping and a reduction can sometimes be parallelised efficiently. The idea is that the mapping part, which usually takes the most time, can be distributed across processors, or even across different machines on a network, while the reduction part is usually fast, and since a reduction uses an associative operation, it doesn't matter in what order the results of the mapping are ready.\n",
    "\n",
    "An example might be that you analyse a set of images from an experiment, where you only care about the total number of particles seen in all the images. The mapping operation takes an image as input, and produces a single number (the particle count) as output. The reduction then just consists of keeping a running total of the counts when they are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "def doubler(x):\n",
    "    return 2*x\n",
    "\n",
    "inputs = np.arange(10)\n",
    "\n",
    "# Produce list of outputs using map\n",
    "# (map returns an iterable, not a list, so converting explicitly)\n",
    "outputs = list(map(doubler, inputs))\n",
    "print(outputs)\n",
    "\n",
    "# Produce the same list of outputs using list comprehension\n",
    "outputs = [doubler(x) for x in inputs]\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce \n",
    "from operator import add\n",
    "\n",
    "# The add function is equivalent to '+', but in function form.\n",
    "print(5+5)\n",
    "print(add(5,5))\n",
    "\n",
    "# The add function takes exactly two arguments\n",
    "# add(5)\n",
    "#add(5, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 45\n",
      "Total = 45\n"
     ]
    }
   ],
   "source": [
    "inputs = np.arange(10)\n",
    "\n",
    "# Apply the add operator to the list of inputs\n",
    "total = reduce(add, inputs)\n",
    "print(f'Total = {total}')\n",
    "\n",
    "# You can achieve the same with the built-in sum function\n",
    "total = sum(inputs)\n",
    "print(f'Total = {total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching several copies of a Python script from another script or notebook\n",
    "\n",
    "There are many different ways to launch multiple copies of a python script (or other program, for that matter). I you just need to run a few simulations, for a few different parameters, it might be easiest to just launch them manually. For more simulations, or if you want to run systematically for a range of input parameters, it might make more sense to set up some scheme for automatically launching simulations. Shell script can be a good tool for this, or you can launch other programs from a Python program with the `subprocess` library. Note that this can be used to launch any program, not just other Python programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processes launched\n",
      "All processes completed\n"
     ]
    }
   ],
   "source": [
    "subprocesses = []\n",
    "for i in range(4):\n",
    "    # start 4 identical copies of the program, and add to list\n",
    "    # note that we could also give them different command line\n",
    "    # arguments by adding more entries in the list of args\n",
    "    # (note that arguments must be strings, not numbers)\n",
    "    args = ['python', '../Python/Parallelisation/wait.py', str(i)]\n",
    "    subprocesses.append( subprocess.Popen(args) )\n",
    "    \n",
    "print('All processes launched')\n",
    "\n",
    "\n",
    "# Wait for all copies to finish before proceeding.\n",
    "# p.wait() does not return until the subprocess is complete.\n",
    "for p in subprocesses:\n",
    "    p.wait()\n",
    "    \n",
    "print('All processes completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping all CPUs busy while running a large number of jobs\n",
    "\n",
    "If you need to run a large number of simulations, it usually makes sense to try to keep all CPUs busy. Say you have 4 CPU cores, then you might want to launch 4 simulations, and as soon as one is finished, you launch another. On Mac and Linux, you can achieve this with the command line tool `xargs` (which I believe is also awailable of modern Windows installations with the Windows subsystem for Linux: https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux ).\n",
    "\n",
    "However, you might also want to write a python script to do the same thing, since this makes it easy to run simulations for different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 subprocesses running\n",
      "2 subprocesses running\n",
      "3 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "0 subprocesses running\n",
      "1 subprocesses running\n",
      "2 subprocesses running\n",
      "3 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "4 subprocesses running\n",
      "0 subprocesses running\n",
      "1 subprocesses running\n",
      "2 subprocesses running\n",
      "All processes launched\n",
      "All processes completed\n"
     ]
    }
   ],
   "source": [
    "# parameters to run simulation for\n",
    "parameters = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "# Max simultaneous runs\n",
    "Nprocs = 4\n",
    "\n",
    "# List to keep track of launched processes\n",
    "subprocesses = []\n",
    "# Number currently running\n",
    "running = 0\n",
    "\n",
    "while len(subprocesses) < len(parameters):\n",
    "    # Check if number of simulations currently running\n",
    "    # is smaller than number of processors\n",
    "    if running < Nprocs:\n",
    "        # Start a simulation\n",
    "        i = len(subprocesses)\n",
    "        args = ['python', '../Python/Parallelisation/wait.py', str(parameters[i])]\n",
    "        subprocesses.append( subprocess.Popen(args))\n",
    "    else:\n",
    "        # Wait a few seconds before checking again\n",
    "        sleep(2)\n",
    "        \n",
    "    # Count number of running processes, by creating a boolean\n",
    "    # array with True for running processes and False for completed\n",
    "    # p.poll() returns None if p is still running,\n",
    "    # and 0 if it has excited successfully\n",
    "    running = sum([p.poll() is None for p in subprocesses])\n",
    "    print(f'{running} subprocesses running')\n",
    "\n",
    "print('All processes launched')\n",
    "\n",
    "\n",
    "# Wait for all copies to finish before proceeding.\n",
    "# p.wait() does not return until the subprocess is complete.\n",
    "for p in subprocesses:\n",
    "    p.wait()\n",
    "    \n",
    "print('All processes completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running multiple copies of a function with the Multiprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Pool\n",
    "\n",
    "# For reasons that are not entirely clear to me,\n",
    "# the multiprocessing module seems to have trouble\n",
    "# with functions defined in a notebook. Therefore,\n",
    "# I have defined a function in a separate file\n",
    "# called example_functions.py, which I import here.\n",
    "import sys\n",
    "sys.path.append('../Python/Parallelisation/')\n",
    "import example_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of inputs for which to run simulation\n",
    "parameters = np.arange(12)\n",
    "\n",
    "processes = []\n",
    "\n",
    "for x in parameters:\n",
    "    # the function is defined in the file wait_function.py,\n",
    "    # see comments above\n",
    "    p = Process(target = example_functions.wait_function, args = (x, ))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "# Wait for all copies to finish before proceeding.\n",
    "# p.join() does not return until the process is complete.\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of inputs for which to run simulation\n",
    "parameters = np.arange(12)\n",
    "\n",
    "# Using a pool of 4 processes will keep\n",
    "# 4 copies of the function running at all times,\n",
    "# until the function has been run for each parameter\n",
    "with Pool(4) as pool:\n",
    "    pool.map(example_functions.wait_function, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelisation with Numba\n",
    "\n",
    "Numba has some support for parallelisation. For example you can parallelise loops by using `prange` instead of `range`. Note that this requires that each iteration in the loop is independent of the other iterations.\n",
    "\n",
    "For additional information, see the Numba documentation: https://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def iterator(z, c, maxiter):\n",
    "    for i in range(maxiter):\n",
    "        z = z*z + c\n",
    "        if abs(z) > 2:\n",
    "            return i\n",
    "    return maxiter\n",
    "\n",
    "@jit(nopython = True)\n",
    "def julia_serial(c, Nx, Ny, xmin=-1.5, xmax=1.5, ymin=-1., ymax=1., maxiter=100):\n",
    "    x = np.linspace(xmin, xmax, Nx)\n",
    "    y = np.linspace(ymin, ymax, Ny)\n",
    "    m = np.empty((Nx, Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            m[i,j] = iterator(z = x[i] + 1j*y[j], c = c, maxiter = maxiter)\n",
    "    return x, y, m\n",
    "\n",
    "@jit(nopython = True, parallel = True)\n",
    "def julia_parallel(c, Nx, Ny, xmin=-1.5, xmax=1.5, ymin=-1., ymax=1., maxiter=100):\n",
    "    x = np.linspace(xmin, xmax, Nx)\n",
    "    y = np.linspace(ymin, ymax, Ny)\n",
    "    m = np.empty((Nx, Ny))\n",
    "    # Note use of prange instead of range\n",
    "    # (requires parallel = True in the @jit decorator)\n",
    "    for i in prange(Nx):\n",
    "        for j in range(Ny):\n",
    "            m[i,j] = iterator(z = x[i] + 1j*y[j], c = c, maxiter = maxiter)\n",
    "    return x, y, m\n",
    "\n",
    "# Force compilation by calling functions here,\n",
    "# to avoid messing up timing later\n",
    "_ = julia_serial(0+1j, 1, 1)\n",
    "_ = julia_parallel(0+1j, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial version:\n",
      "1.42 s ± 24.9 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n",
      "Parallel version:\n",
      "384 ms ± 1.82 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "Nx = 3000\n",
    "Ny = 2000\n",
    "c = 0.02 + 1j*0.4\n",
    "\n",
    "print('Serial version:')\n",
    "%timeit -n1 -r5 x, y, m = julia_serial(c, Nx, Ny)\n",
    "\n",
    "print('Parallel version:')\n",
    "%timeit -n1 -r5 x, y, m = julia_parallel(c, Nx, Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def diffusion_serial(C0, D, v, X, T):\n",
    "    # Make a copy to avoid overwriting the initial condition\n",
    "    C = C0.copy()\n",
    "    # Find dx and dt (assuming constant spacing)\n",
    "    dx = X[1] - X[0]\n",
    "    dt = T[1] - T[0]\n",
    "    # Run simulation for each value in T\n",
    "    for i in range(len(T)):\n",
    "        # Make a new empty array to hold the updated values\n",
    "        Cnew = np.empty_like(C)\n",
    "        # Using a for-loop to begin with\n",
    "        # Handle interior points first\n",
    "        for i in range(1, len(C)-1):\n",
    "            Cnew[i] = C[i] + dt*(D*(C[i+1] - 2*C[i] + C[i-1])/dx**2  -  v*(C[i+1] - C[i-1])/(2*dx))\n",
    "        # Then, handle boundary points to get periodic BC\n",
    "        Cnew[ 0] = C[ 0] + dt*(D*(C[1] - 2*C[ 0] + C[-1])/dx**2  -  v*(C[1] - C[-1])/(2*dx))\n",
    "        Cnew[-1] = C[-1] + dt*(D*(C[0] - 2*C[-1] + C[-2])/dx**2  -  v*(C[0] - C[-2])/(2*dx))\n",
    "        # Finally, copy values back into C\n",
    "        C = Cnew\n",
    "    # Return results at\n",
    "    return C\n",
    "\n",
    "@jit(nopython=True, parallel = True)\n",
    "def diffusion_parallel(C0, D, v, X, T):\n",
    "    # Make a copy to avoid overwriting the initial condition\n",
    "    C = C0.copy()\n",
    "    # Find dx and dt (assuming constant spacing)\n",
    "    dx = X[1] - X[0]\n",
    "    dt = T[1] - T[0]\n",
    "    # Run simulation for each value in T\n",
    "    for i in range(len(T)):\n",
    "        # Make a new empty array to hold the updated values\n",
    "        Cnew = np.empty_like(C)\n",
    "        # Using a for-loop to begin with\n",
    "        # Handle interior points first\n",
    "        # Note use of prange instead of range here\n",
    "        for i in prange(1, len(C)-1):\n",
    "            Cnew[i] = C[i] + dt*(D*(C[i+1] - 2*C[i] + C[i-1])/dx**2  -  v*(C[i+1] - C[i-1])/(2*dx))\n",
    "        # Then, handle boundary points to get periodic BC\n",
    "        Cnew[ 0] = C[ 0] + dt*(D*(C[1] - 2*C[ 0] + C[-1])/dx**2  -  v*(C[1] - C[-1])/(2*dx))\n",
    "        Cnew[-1] = C[-1] + dt*(D*(C[0] - 2*C[-1] + C[-2])/dx**2  -  v*(C[0] - C[-2])/(2*dx))\n",
    "        # Finally, copy values back into C\n",
    "        C = Cnew\n",
    "    # Return results at\n",
    "    return C\n",
    "\n",
    "# Force compilation by calling functions here,\n",
    "# to avoid messing up timing later\n",
    "_ = diffusion_serial(np.linspace(0,1,10), 1e-3, 1e-3, np.linspace(0, 1, 10), np.linspace(0, 1, 10))\n",
    "_ = diffusion_parallel(np.linspace(0,1,10), 1e-3, 1e-3, np.linspace(0, 1, 10), np.linspace(0, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D dt/dx**2 = 0.5000\n",
      "Serial version:\n",
      "606 ms ± 41.1 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "Parallel version:\n",
      "326 ms ± 78.5 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Set up and run simulation\n",
    "D = 0.0001 # Diffusivity\n",
    "v = 0.01 # Advection velocity\n",
    "T = np.linspace(0, 1, 20001) # time coordinates\n",
    "X = np.linspace(0, 1, 10001) # x coordinates\n",
    "# Initial concentration\n",
    "mu = 0.5\n",
    "sigma = 0.1\n",
    "C0 = (1/(sigma*np.sqrt(2*np.pi))) * np.exp(-(X - mu)**2 / (2*sigma**2))\n",
    "\n",
    "# Check stability (this number should be smaller than 1/2)\n",
    "print(f'D dt/dx**2 = {D*(T[1]-T[0])/(X[1]-X[0])**2:.4f}')\n",
    "\n",
    "print('Serial version:')\n",
    "%timeit -n1 -r3 C = diffusion_serial(C0, D, v, X, T)\n",
    "\n",
    "print('Parallel version:')\n",
    "%timeit -n1 -r3 C = diffusion_parallel(C0, D, v, X, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU parallelisation (Cuda) with numba\n",
    "\n",
    "GPU parallelisation takes advantage of the graphics processor, which can accelerate some tasks. A few points to keep in mind:\n",
    "* GPUs typically have a large number of cores (several thousand in high-end GPUs)\n",
    "* GPUs typically have a limited amount of memory per core (often around 10 MB/core, compared to several GB/core for a typical laptop CPU)\n",
    "* GPUs might not support double precision (or only supported with reduced performance)\n",
    "* Data must be transfered from the main memory of the computer to the GPU memory before computations start, and back again afterwards.\n",
    "\n",
    "In summary, this means that GPU parallelisation is extremely well suited to some tasks, and not at all suited to other tasks. The best problems are those where there is not too much memory required, and the problem can be split into very many small and independent sub-problems. A typical use case is where you have an array of data, and you want to perform some operation on the array, where the operation on each element is independent of the operations on the other elements. To run code on the GPU, you will typically write a so-called \"kernel\", which is essentially a function that runs on the GPU. The kernel is executed on each core (of which there may be thousands), and operates on a small part, or even a single element, of the input array.\n",
    "\n",
    "Numba provides support for GPU parallelisation with Cuda. This requires that you have an Nvidia GPU, and that you have Cuda drivers already installed. Experimental support for AMD GPUs is also available.\n",
    "\n",
    "See the documentation for further details: https://numba.pydata.org/numba-doc/dev/user/index.html\n",
    "\n",
    "**Note:** You will only be able to run the cuda examples below if you have an Nvidia GPU and the correct drivers installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5c62d7eed441>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print the name of the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Device list is not initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Query all CUDA devices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mnumdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             gpus = [_DeviceContextManager(driver.get_device(devid))\n\u001b[1;32m     28\u001b[0m                     for devid in range(numdev)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mget_device_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuDeviceGetCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n\u001b[0m\u001b[1;32m    286\u001b[0m                                    self.initialization_error)\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "from numba import cuda, vectorize, float32, float64, int32, complex64\n",
    "\n",
    "# print the name of the device\n",
    "cuda.gpus.lst[0]._device.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Parallel Mandelbrot set with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize('int32(complex64)')\n",
    "def mandelbrot_cpu(c):\n",
    "    maxiter = 100\n",
    "    z = 0.0 + 0*1j\n",
    "    for i in range(maxiter):\n",
    "        z = z*z + c\n",
    "        if abs(z) > 2:\n",
    "            return i\n",
    "    return maxiter\n",
    "\n",
    "@vectorize('int32(complex64)', target ='cuda')\n",
    "def mandelbrot_gpu(c):\n",
    "    maxiter = 100\n",
    "    z = 0.0 + 0*1j\n",
    "    for i in range(maxiter):\n",
    "        z = z*z + c\n",
    "        if abs(z) > 2:\n",
    "            return i\n",
    "    return maxiter\n",
    "\n",
    "# Call both functions once to force compilation here\n",
    "c = np.complex64(0 + 1j)\n",
    "_ = mandelbrot_cpu(c)\n",
    "_ = mandelbrot_gpu(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nx, Ny = 1500, 1000\n",
    "xmin, xmax = -2.2, 1.2\n",
    "ymin, ymax = -1.3, 1.3\n",
    "x = np.linspace(xmin, xmax, Nx)\n",
    "y = np.linspace(ymin, ymax, Ny)\n",
    "\n",
    "C = (x[:,None] + 1j*y[None,:]).astype(np.complex64)\n",
    "\n",
    "M = mandelbrot_gpu(C)\n",
    "\n",
    "fig = plt.figure(figsize = (12, 8))\n",
    "plt.pcolormesh(x, y, M.T, shading = 'auto', cmap = 'plasma_r')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CPU version:')\n",
    "%timeit M = mandelbrot_cpu(C)\n",
    "\n",
    "print('GPU version')\n",
    "%timeit M = mandelbrot_gpu(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: 2D Diffusion equation on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit('(float32[:,:], float32[:,:], float32, float32, float32)')\n",
    "#@cuda.jit('(float64[:,:], float64[:,:], float64, float64, float64)')\n",
    "def FTCS_gpu(C_now, C_next, D, dt, dx):\n",
    "    # Get array bounds\n",
    "    Nx, Ny = C_now.shape\n",
    "    # Get the cell of this thread\n",
    "    i, j = cuda.grid(2)\n",
    "    # First, check that i and j are within bounds\n",
    "    if ((0 <= i) and (i < Nx)) and ((0 <= j) and (j < Ny)):\n",
    "        # Then, update this cell, using division modulo Nx and Ny\n",
    "        # implement periodic boundary conditions\n",
    "        alpha =  D*dt/dx**2\n",
    "        C_next[i,j] = C_now[i,j] + alpha*(\n",
    "             C_now[(i+1)%Nx, j]\n",
    "            +C_now[(i-1)%Nx, j] \n",
    "            +C_now[i, (j+1)%Ny] \n",
    "            +C_now[i, (j-1)%Ny]\n",
    "            -4*C_now[i,j]\n",
    "        )\n",
    "        \n",
    "def diffusion_solver_gpu(C0, D, Tmax, dt, dx):\n",
    "    # Define working precision\n",
    "    WP = np.float32\n",
    "    # Create two arrays on the GPU, of the desired precision\n",
    "    d_C_now = cuda.to_device(C0.astype(WP))\n",
    "    d_C_next = cuda.device_array_like(C0.astype(WP))\n",
    "    # Make copies of parameters in working precision\n",
    "    d_D  = WP(D)\n",
    "    d_dt = WP(dt)\n",
    "    d_dx = WP(dx)\n",
    "    \n",
    "    # Number of threads per block\n",
    "    threads = (32, 32)\n",
    "    # Calculate number of blocks needed to match size of array\n",
    "    Nx, Ny = C0.shape\n",
    "    blocks = (\n",
    "        int(Nx/threads[0]) if Nx%threads[0] == 0 else int(Nx/threads[0])+1,\n",
    "        int(Ny/threads[1]) if Ny%threads[1] == 0 else int(Ny/threads[1])+1,\n",
    "    )\n",
    "    \n",
    "    # Then, loop over time\n",
    "    Nt = int(Tmax/dt)\n",
    "    for i in range(Nt):\n",
    "        # One iteration with the FTCS method\n",
    "        FTCS_gpu[blocks, threads](d_C_now, d_C_next, d_D, d_dt, d_dx)\n",
    "        # Then update arrays\n",
    "        d_C_now = d_C_next\n",
    "    \n",
    "    # Copy results back to main memory\n",
    "    C = d_C_now.copy_to_host()\n",
    "    \n",
    "    return C\n",
    "\n",
    "\n",
    "def diffusion_solver_cpu(C0, D, Tmax, dt, dx):\n",
    "    # Work arrays\n",
    "    C_now = C0.copy()\n",
    "    C_next = np.zeros_like(C0)\n",
    "    # Prefactor\n",
    "    WP = np.float32\n",
    "    alpha =  WP(D)*WP(dt)/WP(dx)**2\n",
    "    # Loop over time\n",
    "    Nt = int(Tmax/dt)\n",
    "    for i in range(Nt):\n",
    "        # One iteration with the FTCS method\n",
    "        # Interior points\n",
    "        C_next[1:-1, 1:-1] = C_now[1:-1, 1:-1] + alpha*(\n",
    "             C_now[2:  , 1:-1]\n",
    "            +C_now[ :-2, 1:-1]\n",
    "            +C_now[1:-1, 2:  ]\n",
    "            +C_now[1:-1,  :-2]\n",
    "            -4*C_now[1:-1, 1:-1]\n",
    "        )\n",
    "        # Boundaries (periodic BC)\n",
    "        C_next[ 0, 1:-1] = C_now[ 0, 1:-1] + alpha*(C_now[1, 1:-1]+C_now[-1, 1:-1]+C_now[ 0, 2:]+C_now[ 0, :-2]-4*C_now[ 0, 1:-1])\n",
    "        C_next[-1, 1:-1] = C_now[-1, 1:-1] + alpha*(C_now[0, 1:-1]+C_now[-2, 1:-1]+C_now[-1, 2:]+C_now[-1, :-2]-4*C_now[-1, 1:-1])\n",
    "        C_next[1:-1,  0] = C_now[1:-1,  0] + alpha*(C_now[2:, 0]+C_now[:-2,  0]+C_now[1:-1, 1]+C_now[1:-1, -1]-4*C_now[1:-1,  0])\n",
    "        C_next[1:-1, -1] = C_now[1:-1, -1] + alpha*(C_now[2:,-1]+C_now[:-2, -1]+C_now[1:-1, 0]+C_now[1:-1, -2]-4*C_now[1:-1, -1])\n",
    "        # Corners (periodic BC)\n",
    "        C_next[ 0, 0] = C_now[ 0, 0] + alpha*(C_now[1, 0]+C_now[-1, 0]+C_now[ 0, 1]+C_now[ 0,-1]-4*C_now[ 0, 0])\n",
    "        C_next[-1, 0] = C_now[-1, 0] + alpha*(C_now[0, 0]+C_now[-2, 0]+C_now[-1, 1]+C_now[-1,-1]-4*C_now[-1, 0])\n",
    "        C_next[ 0,-1] = C_now[ 0,-1] + alpha*(C_now[1,-1]+C_now[-1,-1]+C_now[ 0, 0]+C_now[ 0,-2]-4*C_now[ 0,-1])\n",
    "        C_next[-1,-1] = C_now[-1,-1] + alpha*(C_now[0,-1]+C_now[-2,-1]+C_now[-1, 0]+C_now[-1,-2]-4*C_now[-1,-1])\n",
    "        \n",
    "        C_now = C_next\n",
    "    \n",
    "    return C_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters\n",
    "Lx = 2\n",
    "Ly = 1\n",
    "Nx = 1024\n",
    "Ny = 512\n",
    "# Timestep\n",
    "dt = 0.001\n",
    "Tmax = 5\n",
    "\n",
    "# Coordinates\n",
    "xc, dx = np.linspace(0, Lx, Nx, retstep = True)\n",
    "yc, dy = np.linspace(0, Ly, Ny, retstep = True)\n",
    "# Grid points\n",
    "gridx, gridy = np.meshgrid(xc, yc)\n",
    "\n",
    "# Diffusivity (constant in space and time)\n",
    "D = 0.0009\n",
    "\n",
    "# Check stability condition for this method\n",
    "print(f'D*dt/dx**2 = {D*dt/dx**2:.5f}, must be less than 0.25')\n",
    "\n",
    "# Initial concentration (gaussian)\n",
    "x0, y0 = 1.87, 0.87\n",
    "sx, sy = 0.05, 0.05\n",
    "# Create concentration field\n",
    "C0 = (np.exp(-(gridx - x0)**2/(2*sx**2) - (gridy-y0)**2/(2*sy**2))).astype(np.float32)\n",
    "\n",
    "tic = time()\n",
    "C_gpu = diffusion_solver_gpu(C0, D, Tmax, dt, dx)\n",
    "toc = time()\n",
    "print(f'GPU Calculation took {toc - tic:.4f} seconds')\n",
    "\n",
    "tic = time()\n",
    "C_cpu = diffusion_solver_cpu(C0, D, Tmax, dt, dx)\n",
    "toc = time()\n",
    "print(f'CPU Calculation took {toc - tic:.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 3, figsize = (9, 12), sharex = True, sharey = True)\n",
    "ax[0].pcolormesh(C0)\n",
    "ax[1].pcolormesh(C_cpu)\n",
    "ax[2].pcolormesh(C_gpu)\n",
    "plt.tight_layout()\n",
    "\n",
    "print('Max difference between solutions: ', np.amax(np.abs(C_cpu - C_gpu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI\n",
    "\n",
    "(As far as I know, it's not possible to run MPI in a jupyter notebook, so this is just to look at some results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at results from the MPI-parallelisation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0_MPI = np.load('../Python/Parallelisation/C0_MPI.npy')\n",
    "C_MPI = np.load('../Python/Parallelisation/C_MPI.npy')\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 2, figsize = (9, 7))\n",
    "ax[0].pcolormesh(C0_MPI.T)\n",
    "ax[1].pcolormesh(C_MPI.T)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measured times, on a machine with 8 physical cores\n",
    "# (and 16 virtual cores via hyperthreading)\n",
    "Ncpus = np.array([1, 2, 4, 8, 16, ])\n",
    "times = np.array([40.83, 15.99, 8.73, 4.97, 3.96, ])\n",
    "\n",
    "plt.plot(Ncpus, times)\n",
    "plt.plot(Ncpus, times[0]/Ncpus, '--', c = 'k', label = 'Optimal scaling')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Number of cores')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.xticks(Ncpus, Ncpus)\n",
    "plt.legend(fontsize = 14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
